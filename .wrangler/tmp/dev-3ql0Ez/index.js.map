{
  "version": 3,
  "sources": ["../../../src/index.ts", "../../../../../../opt/homebrew/lib/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../../../../opt/homebrew/lib/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../bundle-AyQuKx/middleware-insertion-facade.js", "../../../../../../opt/homebrew/lib/node_modules/wrangler/templates/middleware/common.ts", "../bundle-AyQuKx/middleware-loader.entry.ts"],
  "sourceRoot": "/Users/sagargopalasetti/interview-worker/.wrangler/tmp/dev-3ql0Ez",
  "sourcesContent": ["/**\n * Cloudflare Worker port of your FastAPI app:\n * - POST /api/generate-cover-letter\n * - POST /api/optimize-resume\n * - POST /api/interview-prep\n * - POST /api/interview-sim\n * - GET  /api/models\n * - GET  /\n *\n * Providers:\n * - Groq (OpenAI-compatible endpoint at https://api.groq.com/openai/v1/chat/completions)\n * - DeepSeek (OpenAI-compatible endpoint at https://api.deepseek.com/v1/chat/completions)\n *\n * Local secrets for `wrangler dev`: put in `.dev.vars`\n *   GROQ_API_KEY=sk-...\n *   DEEPSEEK_API_KEY=sk-...   # only if you use deepseek-chat\n */\n\nexport interface Env {\n  GROQ_API_KEY: string;        // required\n  DEEPSEEK_API_KEY?: string;   // only if using deepseek-chat\n  ALLOWED_ORIGIN?: string;     // optional CORS origin\n}\n\nconst JSON_CT = \"application/json; charset=utf-8\";\nconst GROQ_CHAT = \"https://api.groq.com/openai/v1/chat/completions\";\nconst DEEPSEEK_CHAT = \"https://api.deepseek.com/v1/chat/completions\";\n\n// ==== Models (same list) ====\nconst MODELS = [\n  \"llama-3.1-8b-instant\",\n  \"deepseek-chat\",\n  \"llama-3.3-70b-versatile\",\n];\n\n// ==== Request Types (user_custom_prompt is optional) ====\ntype CoverLetterRequest = {\n  resume: string;\n  job_description: string;\n  model_name: string;\n  user_custom_prompt?: string;\n};\n\ntype ResumeOptimizationRequest = {\n  resume: string;\n  job_description: string;\n  model_name: string;\n  resume_section: string;\n  user_custom_prompt?: string;\n};\n\ntype InterviewPrepRequest = {\n  resume: string;\n  job_description: string;\n  interviewer_role: string;\n  interviewer_profile: string;\n  interview_duration: number;\n  interview_description: string;\n  model_name: string;\n  user_custom_prompt?: string;\n};\n\ntype InterviewSimulationRequest = {\n  resume: string;\n  job_description: string;\n  interview_type: string;\n  interviewer_role: string;\n  interviewer_profile: string;\n  interview_duration: number;\n  interview_description: string;\n  model_name: string;\n  user_custom_prompt?: string;\n};\n\n// ======================\n// Prompt Templates (1:1)\n// ======================\n\n// --- COVER LETTER ---\nconst COVER_LETTER_TEMPLATE = `\nYou are an expert cover letter writer at a top recruiting firm specializing in ATS optimization. \nYour task is to craft a compelling cover letter that strictly uses information from the provided \nresume to match the job description requirements.\n\nResume:\n{resume}\n\nJob Description:\n{job_description}\n\nUser's Custom Requirements:\n{user_custom_prompt}\n\nFollow these precise guidelines:\n\n1. OPENING PARAGRAPH:\n- Begin with a strong introduction referencing the specific job title\n- Mention how you discovered the position\n- Include a brief (1-2 sentence) summary of your most relevant qualification from the resume\n\n2. BODY PARAGRAPHS (2-3):\n- Each paragraph must reference specific accomplishments from the resume\n- Format: Situation -> Action -> Result\n- Use metrics and achievements mentioned in the resume\n- Connect each point directly to job requirements\n- Only include information present in the resume\n\n3. CLOSING PARAGRAPH:\n- Summarize why you're an excellent fit based on resume qualifications\n- Express enthusiasm for the opportunity\n- Include clear call to action\n\nSTRICT REQUIREMENTS:\n- Divide the cover letter into paragraphs \n- Do not bold or italicize any text not even the headings, subject line, names, salutations, or closing or any other text\n- Must use formal business letter format\n- Every claim must be verifiable from the resume\n- Use active voice and professional tone\n- Avoid generic statements that could apply to any candidate\n\nPROHIBITED:\n- Adding skills or experiences not mentioned in the resume\n- Generic phrases or clich\u00E9s\n- Bolding or italicizing text \n- Unsubstantiated claims\n- Personal information not related to professional qualifications\n`;\n\n// --- RESUME OPTIMIZATION (JSON) ---\nconst RESUME_OPTIMIZATION_TEMPLATE = `\nYou are an expert resume analyst and career coach with deep experience in talent acquisition and job matching. \nYour task is to analyze the provided resume section against the job description and provide detailed, actionable \nfeedback.\n\nResume Section to Analyze: {resume_section}\nJob Description: {job_description}\nCustom User Prompt (if any): {user_custom_prompt}\n\nAnalysis Steps for Each Section:\n\nSECTION 1 - NEW POINTS SUGGESTIONS: Suggest atleast 6 new points covering all the subsections of the resume section. \n1. Gap Analysis:\n   - Compare job requirements against current resume content\n   - Identify missing critical experiences\n   - Note unexpressed relevant achievements\n\n2. Point Generation:\n   - Focus on gaps identified in job requirements\n   - Leverage candidate's background for relevant examples\n   - Ensure alignment with industry standards\n   - Include specific metrics and technical details\n\n3. Validation:\n   - Verify each suggestion is realistic given the experience\n   - Ensure alignment with job requirements\n   - Confirm measurable impact inclusion\n   - Check technical keyword relevance\n\nSECTION 2 - KEYWORD ANALYSIS:\n1. Keyword Extraction:\n   First, extract ALL important keywords from the job description that are valuable for ATS/Recruiter evaluation:\n   - Must extract ALL technical skills and technologies mentioned\n   - ALL programming languages and frameworks\n   - ALL tools, platforms, and software\n   - ALL methodologies and processes\n   - ALL soft skills that appear multiple times or are emphasized\n   - ALL industry-specific terminology\n   - ALL required certifications\n   - ANY keywords that appear to be emphasized or repeated in the job description\n   \n2. Comprehensive Matching Process:\n   For EACH extracted keyword:\n   - Perform case-insensitive exact match check in the resume section\n   - Mark as \"Yes\" if present in ANY form\n   - Mark as \"No\" if absent\n   - You must include EVERY important keyword in the output, regardless of whether it's present or not\n   \n3. Recommendation Formation:\n   For EACH \"No\" keyword:\n   - Create a specific bullet point showing how to incorporate the keyword\n   - Identify the most relevant subsection for placement\n   - Explain why this placement makes sense\n   - Ensure the recommendation aligns with the candidate's actual experience\n   \nIMPORTANT OUTPUT FORMATTING INSTRUCTIONS:\n1. Return ONLY pure JSON without any additional formatting characters\n2. Do NOT include \\`\\`\\`json, \\\\n, or any other markdown/formatting syntax\n3. The response should start directly with the opening curly brace\n4. Ensure proper JSON escaping for any special characters\n5. Do not add any text before or after the JSON object\n\nFormat your response as a clean JSON object:\n{{\n    \"analysis_results\": {{\n        \"section_1\": {{\n            \"title\": \"Suggested New Points\",\n            \"suggestions\": [\n                {{\n                    \"bullet_point\": \"<detailed point with metrics and technical keywords>\",\n                    \"rationale\": \"<specific gap or requirement addressed>\",\n                    \"alignment\": \"<relevant job requirements and how this point meets them and where it can be placed in the resume>\"\n                }}\n            ]\n        }},\n        \"section_2\": {{\n            \"title\": \"Keyword Analysis\",\n            \"keywords\": [\n                {{\n                    \"key_term\": \"<extract EVERY important keyword from job description>\",\n                    \"present_in_resume\": \"<strictly Yes or No>\",\n                    \"recommendation\": \"<Required if No: provide specific bullet point for incorporating this keyword>\",\n                    \"placement_reasoning\": \"<Required if No: specify exact subsection and detailed reasoning for placement>\"\n                }}\n            ]\n        }}\n    }}\n}}\n\nAdditional Requirements for Section 3:\n1. Include ALL important keywords from job description, not just matches\n2. Ensure \"present_in_resume\" is ALWAYS either \"Yes\" or \"No\"\n3. For \"No\" matches, ALWAYS provide both recommendation and placement_reasoning\n4. For \"Yes\" matches, set recommendation and placement_reasoning to \"Already present in resume\"\n5. Keywords should be listed in order of importance/frequency in job description\n6. Include technical terms, soft skills, and methodologies\n7. Do not skip any important keyword, even if it seems minor\n\nCritical and Strict Requirements:\n1. Start response directly with {{ and end with }}\n2. No markdown formatting (\\`\\`\\`), newline characters (\\\\n), or other special formatting\n3. No additional text outside the JSON object\n4. Ensure all JSON syntax is valid and properly nested\n5. Use proper escaping for quotes and special characters within strings\n`;\n\n// --- func2 (Existing Points Optimization, JSON) ---\nconst FUNC2_PROMPT_TEMPLATE = `\nYou are an expert resume analyst and career coach with deep experience in talent acquisition and job matching. \nYour task is to analyze the provided resume section against the job description and provide detailed, actionable \nfeedback.\n\nResume Section to Analyze: {resume_section}\nJob Description: {job_description}\nCustom User Prompt (if any): {user_custom_prompt}\n\nAnalysis Steps for Each Section:\n\nSECTION 1 - EXISTING POINTS OPTIMIZATION:\n1. Mandatory Subsection Detection (CRITICAL):\n   a. First pass - Identification:\n      - Scan for ALL experience entries containing:\n        * Company name AND\n        * Role/title AND\n        * Date range\n      - Create a LIST of ALL detected experiences\n      - Count total number of experiences found\n   \n   b. Second pass - Validation:\n      - Compare detected experiences against original text\n      - Confirm NO experiences were missed\n      - Record exact count of bullet points per experience\n      - REQUIRE minimum 4 distinct subsections for typical resume\n      - Flag if fewer subsections found than exist in input\n\n   c. Quality Check:\n      - Assert all date ranges are accounted for\n      - Verify no content exists outside detected subsections\n      - Confirm all experiences have associated bullet points\n\n2. Comprehensive Analysis Requirements:\n   For EACH subsection identified above:\n   - Must process ALL bullet points\n   - Must analyze EVERY subsection detected\n   - Cannot skip or combine subsections\n   - Must maintain chronological order\n   - Must process most recent to oldest experience\n\n3. For each bullet point in EVERY subsection:\n   Analyze and improve based on:\n   - Quantifiable metrics presence and effectiveness\n   - Impact demonstration (business value, outcomes)\n   - Action verb strength and specificity\n   - Technical keyword inclusion and relevance\n   - Alignment with job requirements\n\n4. For bullet points needing improvement:\n   - Identify specific weaknesses\n   - Add missing metrics where possible\n   - Strengthen action verbs\n   - Enhance technical detail\n   - Improve alignment with job requirements\n\n5. For effective bullet points:\n   - Document why they work well\n   - Note specific elements that make them strong\n\nIMPORTANT OUTPUT FORMATTING INSTRUCTIONS:\n1. Return ONLY pure JSON without any additional formatting characters\n2. Do NOT include \\`\\`\\`json, \\\\n, or any other markdown/formatting syntax\n3. The response should start directly with the opening curly brace\n4. Ensure proper JSON escaping for any special characters\n5. Do not add any text before or after the JSON object\n\nFormat your response as a clean JSON object:\n{{\n    \"analysis_results\": {{\n        \"section_1\": {{\n            \"title\": \"Existing Points Optimization\",\n            \"subsections\": [\n                {{\n                    \"subsection_name\": \"<company/role name>\",\n                    \"points\": [\n                        {{\n                            \"original\": \"<original bullet point>\",\n                            \"improved\": \"<enhanced version with metrics, stronger verbs, and job alignment>\",\n                            \"reasoning\": \"<specific improvements made and their value>\"\n                        }}\n                    ],\n                    \"unchanged_points\": [\n                        {{\n                            \"point\": \"<bullet point>\",\n                            \"assessment\": \"<specific elements that make it effective>\"\n                        }}\n                    ]\n                }}\n            ]\n        }}\n    }}\n}}\n`;\n\n// --- INTERVIEW PREP (JSON) ---\nconst INTERVIEW_PREP_TEMPLATE = `\nYou are a senior interview coach who has helped 1000+ candidates successfully prepare for \ninterviews at top companies. Create a comprehensive interview preparation guide.\n\nThis is candidate's Resume: \n{resume}\n\nThis is the Job Description:\n{job_description}\n\nInterview Context:\n- Interviewer: {interviewer_role} - {interviewer_profile}\n- Duration: {interview_duration} minutes\n- Format: {interview_description}\n- User's Custom Prompt: {user_custom_prompt}\n\nYou will analyze the provided information and generate a response in the specified JSON format below.\nDo not include any text, prefixes, or explanations outside the JSON structure.\nEnsure the response is a single, valid JSON object.\n\nPREPARATION FRAMEWORK:\n1. STRATEGIC ANALYSIS\nFirst analyze:\nA. Experience Alignment\n   - Map resume experiences to job requirements\n   - Identify potential experience gaps\n   - List strongest achievements relevant to role\nB. Interview Context Analysis\n   - Interviewer's perspective based on their role\n   - Time management strategy for {interview_duration} minutes\n   - Critical areas based on interview type\n\n2. PREPARATION GUIDE\nStructure the preparation into:\nA. Technical Preparation (if applicable)\n   - Core concepts to review\n   - Practice exercises\n   - System design considerations\n   - Coding language specifics\nB. Experience Preparation\n   - Key projects to highlight\n   - Metrics to memorize\n   - Challenge-solution stories\n   - Leadership examples\nC. Company/Role Preparation\n   - Industry trends\n   - Company background\n   - Role-specific knowledge\n   - Expected challenges\n\n3. QUESTION PREDICTION & PREPARATION\nGenerate three types of questions:\nA. Guaranteed Questions (80% likelihood)\n   - Based on job requirements\n   - Based on resume experiences\n   - Standard for interview type\nB. Likely Questions (50% likelihood)\n   - Based on interviewer's role\n   - Based on industry trends\n   - Based on company challenges\nC. Preparation Questions\n   - Technical concepts to review\n   - Projects to prepare discussing\n   - Metrics to remember\n4. ANSWER FRAMEWORKS\nFor each predicted question:\nA. Structure:\n   - Opening statement\n   - Key points to cover\n   - Supporting evidence from resume\n   - Conclusion/impact\nB. Delivery Notes:\n   - Time allocation\n   - Key phrases to use\n   - Data points to include\n   - Follow-up considerations\n\nOUTPUT:\n{\n  \"strategic_analysis\": {\n    \"experience_alignment\": {\n      \"matching_experiences\": [\n        {\n          \"requirement\": \"\",\n          \"matching_experience\": \"\",\n          \"strength_level\": \"\"\n        }\n      ],\n      \"potential_gaps\": [\n        {\n          \"gap\": \"\",\n          \"mitigation_strategy\": \"\"\n        }\n      ],\n      \"key_achievements\": [\n        {\n          \"achievement\": \"\",\n          \"relevance\": \"\"\n        }\n      ]\n    },\n    \"interview_context\": {\n      \"interviewer_perspective\": {\n        \"key_interests\": [],\n        \"likely_focus_areas\": []\n      },\n      \"time_management\": {\n        \"introduction\": 0,\n        \"main_discussion\": 0,\n        \"questions\": 0,\n        \"closing\": 0\n      },\n      \"critical_areas\": []\n    }\n  },\n  \"preparation_guide\": {\n    \"technical_preparation\": {\n      \"core_concepts\": [\n        {\n          \"concept\": \"\",\n          \"importance\": \"\",\n          \"review_materials\": []\n        }\n      ],\n      \"practice_exercises\": [\n        {\n          \"topic\": \"\",\n          \"recommended_problems\": []\n        }\n      ],\n      \"system_design\": {\n        \"key_considerations\": [],\n        \"practice_scenarios\": []\n      }\n    },\n    \"experience_preparation\": {\n      \"key_projects\": [\n        {\n          \"project\": \"\",\n          \"relevance\": \"\",\n          \"key_points\": [],\n          \"metrics\": []\n        }\n      ],\n      \"stories\": [\n        {\n          \"category\": \"\",\n          \"situation\": \"\",\n          \"task\": \"\",\n          \"action\": \"\",\n          \"result\": \"\"\n        }\n      ]\n    },\n    \"company_preparation\": {\n      \"industry_trends\": [],\n      \"company_background\": {\n        \"key_points\": [],\n        \"recent_developments\": []\n      },\n      \"role_specific\": {\n        \"key_responsibilities\": [],\n        \"expected_challenges\": []\n      }\n    }\n  },\n  \"questions\": {\n    \"guaranteed_questions\": [\n      {\n        \"question\": \"\",\n        \"answer_framework\": {\n          \"opening\": \"\",\n          \"key_points\": [],\n          \"evidence\": [],\n          \"conclusion\": \"\"\n        },\n        \"delivery_notes\": {\n          \"time_allocation\": \"\",\n          \"key_phrases\": [],\n          \"data_points\": []\n        }\n      }\n    ],\n    \"likely_questions\": [\n      {\n        \"question\": \"\",\n        \"answer_framework\": {\n          \"opening\": \"\",\n          \"key_points\": [],\n          \"evidence\": [],\n          \"conclusion\": \"\"\n        },\n        \"delivery_notes\": {\n          \"time_allocation\": \"\",\n          \"key_phrases\": [],\n          \"data_points\": []\n        }\n      }\n    ],\n    \"preparation_questions\": {\n      \"technical_review\": [],\n      \"project_discussion\": [],\n      \"metrics_to_remember\": []\n    }\n  }\n}\n\nIMPORTANT NOTES FOR MODEL:\n1. Provide output as a pure JSON object without any prefixes, suffixes, or explanatory text\n2. Strictly do not provide preambles, explanations, or additional information outside the JSON structure. \n2. Do not include 'json\\\\n' or any other formatting prefixes\n3. Fill all fields with relevant content based on the provided information\n4. Ensure arrays are properly formatted, even if empty\n5. Use double quotes for all strings in JSON\n6. Do not include any markdown formatting or code blocks\n7. Maintain proper JSON structure and nesting\n8. Remove any null or undefined values\n`;\n\n// --- INTERVIEW SIM (JSON) ---\nconst INTERVIEW_SIM_TEMPLATE = `\nYou are an experienced interviewer conducting an interview. You will simulate a realistic interview based on:\n\nInput Parameters:\n- Resume: {resume} (Candidate's background and experience)\n- Job Description: {job_description} (Role requirements and expectations) \n- Interview Type: {interview_type} (Style and format of interview)\n- Interviewer Role: {interviewer_role} (Your role as the interviewer)\n- Interviewer Profile: {interviewer_profile} (Your background and expertise)\n- Interview Duration: {interview_duration} (Length of interview)\n- Interview Description: {interview_description} (Specific interview guidelines)\n- Custom Instructions: {user_custom_prompt} (Additional requirements)\n\nInterview Simulation Guidelines:\n\n1. Role Embodiment:\n- Fully embody the specified interviewer role and expertise level.\n- Maintain consistent personality throughout the interview.\n- Consider the company culture and position requirements from Job Description.\n- Follow the specified interview format and duration.\n\n2. Question Strategy:\n- Generate 12-15 strategically sequenced questions\n- Begin with rapport-building questions before diving deep.\n- Answer every question with a detailed and in-depth STAR response.\n- Strictly include questions related to the type of interview mentioned by the user - {interview_type} \n- Keep in mind the candidate's background from Resume and the Job Description.\n- Follow up on relevant points from previous answers.\n- After each response, provide 3-4 follow-up questions related to the candidate's response to deepen the discussion.  \n\n3. Response Generation:\n- Create detailed candidate responses following STAR format:\n * Situation: Set the context and background\n * Task: Explain the specific challenge or responsibility\n * Action: Detail the steps taken to address the situation\n * Result: Share the outcomes and learnings\n- Ensure responses demonstrate:\n * Clear problem-solving approach\n * Technical depth where appropriate\n * Leadership and teamwork skills\n * Decision-making process\n- Generate 3-4 relevant follow-up questions after each response\n\n4. Interview Focus:\n- Maintain clear progression of topics\n- Ensure technical depth aligns with role requirements\n- Focus on real-world scenarios and examples\n- Build upon previous responses for context\n- Keep engagement professional and constructive\n\nThe simulation should maintain professional tone while creating a realistic interview \nenvironment relevant to the candidate's background and the job requirements. . Each response must strictly follow \nthe STAR methodology with detailed answers.\n\nFormat your response as a JSON object with the following structure:\n\n{\n  \"interview_metadata\": {\n    \"position\": string,\n    \"interview_type\": string,\n    \"interviewer\": string,\n    \"duration\": string\n  },\n  \"interview_summary\": {\n    \"candidate_background\": string,\n    \"job_fit_analysis\": string\n  },\n  \"interview_exchange\": [\n    {\n      \"question_number\": number,\n      \"interviewer_question\": string,\n      \"candidate_response\": {\n        \"situation\": string,\n        \"task\": string,\n        \"action\": string,\n        \"result\": string\n      },\n      \"potential_follow_ups\": [\n        string,\n        string,\n        string,\n        string\n      ]\n    }\n  ]\n}\n\nGenerate at least 12-15 questions.\nEnsure each response strictly follows STAR format with elaborate details for each component.\nInclude 3-4 potential follow-up questions after each response.\nGenerate detailed, context-aware responses that demonstrate understanding of both the \ntechnical and soft skills required for the position.\n\n- Do not deviate from the JSON format. Do not give any extra output apart from a valid JSON. \n- Do not include any markdown or code blocks.\n- Do not include any additional text or explanations outside the JSON structure.\n\nCritical Requirements:\n1. Start response directly with { and end with }\n2. No markdown formatting (\\`\\`\\`), newline characters (\\\\n), or other special formatting\n3. No additional text outside the JSON object\n4. Ensure all JSON syntax is valid and properly nested\n5. Use proper escaping for quotes and special characters within strings\n6. The response should start directly with the opening curly brace\n7. Do not add any text before or after the JSON object\n8. Start response directly with { and end with }\n`;\n\n// =========================\n// Utility: simple templater\n// =========================\nfunction render(tpl: string, vars: Record<string, string | number | undefined>): string {\n  return tpl.replace(/\\{(\\w+)\\}/g, (_, k) => String(vars[k] ?? \"\"));\n}\n\n// ======================\n// LLM routing (Groq/DS)\n// ======================\nasync function chat(\n  env: Env,\n  modelName: string,\n  messages: Array<{ role: \"system\" | \"user\" | \"assistant\"; content: string }>,\n  temperature = 0.3,\n  max_tokens = 8000\n): Promise<string> {\n  if (modelName === \"deepseek-chat\") {\n    if (!env.DEEPSEEK_API_KEY) throw new Error(\"DeepSeek requested but DEEPSEEK_API_KEY is not set.\");\n    const resp = await fetch(DEEPSEEK_CHAT, {\n      method: \"POST\",\n      headers: {\n        authorization: `Bearer ${env.DEEPSEEK_API_KEY}`,\n        \"content-type\": \"application/json\",\n      },\n      body: JSON.stringify({ model: \"deepseek-chat\", temperature, max_tokens, messages }),\n    });\n    if (!resp.ok) throw new Error(`DeepSeek error ${resp.status}: ${await resp.text()}`);\n    const data: any = await resp.json();\n    return data?.choices?.[0]?.message?.content ?? \"(No content)\";\n  }\n\n  // Default \u2192 Groq\n  if (!env.GROQ_API_KEY) throw new Error(\"GROQ_API_KEY is not set.\");\n  const resp = await fetch(GROQ_CHAT, {\n    method: \"POST\",\n    headers: {\n      authorization: `Bearer ${env.GROQ_API_KEY}`,\n      \"content-type\": \"application/json\",\n    },\n    body: JSON.stringify({ model: modelName, temperature, max_tokens, messages }),\n  });\n  if (!resp.ok) throw new Error(`Groq error ${resp.status}: ${await resp.text()}`);\n  const data: any = await resp.json();\n  return data?.choices?.[0]?.message?.content ?? \"(No content)\";\n}\n\n// ======================\n// HTTP helpers\n// ======================\nasync function asJson<T>(request: Request): Promise<T> {\n  const ct = request.headers.get(\"content-type\") || \"\";\n  if (!ct.includes(\"application/json\")) throw new Error(\"Use application/json\");\n  // DOM typing: json() has no generic; cast the result\n  return (await request.json()) as T;\n}\n\nfunction requireFields(obj: Record<string, unknown>, keys: string[]) {\n  const missing = keys.filter((k) => obj[k] === undefined || obj[k] === null || obj[k] === \"\");\n  if (missing.length) throw new Error(`Missing: ${missing.join(\", \")}`);\n}\n\nfunction corsHeaders(env: Env) {\n  const h = new Headers();\n  h.set(\"Access-Control-Allow-Origin\", env.ALLOWED_ORIGIN || \"*\");\n  h.set(\"Access-Control-Allow-Methods\", \"GET,POST,OPTIONS\");\n  h.set(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\");\n  h.set(\"Access-Control-Max-Age\", \"86400\");\n  return h;\n}\n\nfunction withCORS(env: Env, res: Response) {\n  const out = new Response(res.body, res);\n  corsHeaders(env).forEach((v, k) => out.headers.set(k, v));\n  return out;\n}\n\nfunction ok(env: Env, data: unknown, status = 200) {\n  return withCORS(env, new Response(JSON.stringify(data), { status, headers: { \"content-type\": JSON_CT } }));\n}\nfunction err(env: Env, status: number, data: unknown) {\n  return withCORS(env, new Response(JSON.stringify(data), { status, headers: { \"content-type\": JSON_CT } }));\n}\n\n// ======================\n// Section extraction\n// ======================\nasync function extractResumeSection(env: Env, rawResume: string, sectionName: string): Promise<string> {\n  const prompt = `\nExtract the exact contents of the '${sectionName}' section from the following resume text. \nDo not modify, paraphrase, or summarize the content after extracting it. \nEnsure the output is an exact match to the text in the specified section.\n\nResume Text:\n${rawResume}\n\nOutput only the content from the '${sectionName}' section.\n  `.trim();\n\n  const content = await chat(\n    env,\n    \"llama-3.3-70b-versatile\",\n    [\n      { role: \"system\", content: \"You are a precise text extractor.\" },\n      { role: \"user\", content: prompt },\n    ],\n    0.0,\n    1200\n  );\n\n  return (content || \"\").trim();\n}\n\n// ======================\n// Optimize existing points (func2)\n// ======================\nasync function optimizeExistingPoints(\n  env: Env,\n  resume_section: string,\n  job_description: string,\n  user_custom_prompt: string | undefined,\n  model_name: string\n): Promise<string> {\n  const rendered = render(FUNC2_PROMPT_TEMPLATE, {\n    resume_section,\n    job_description,\n    user_custom_prompt: user_custom_prompt || \"(none)\",\n  });\n\n  return await chat(\n    env,\n    model_name,\n    [\n      {\n        role: \"system\",\n        content:\n          \"You are an expert resume analyst and career coach with deep experience in talent acquisition and job matching.\",\n      },\n      { role: \"user\", content: rendered },\n    ],\n    0.3,\n    8000\n  );\n}\n\n// ======================\n// Worker routes\n// ======================\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    if (request.method === \"OPTIONS\") return withCORS(env, new Response(null, { status: 204 }));\n\n    const { pathname } = new URL(request.url);\n\n    try {\n      // Health\n      if (request.method === \"GET\" && pathname === \"/\") {\n        return ok(env, { message: \"Hello, World!\" });\n      }\n\n      // Models\n      if (request.method === \"GET\" && pathname === \"/api/models\") {\n        return ok(env, { models: MODELS });\n      }\n\n      // Generate Cover Letter\n      if (request.method === \"POST\" && pathname === \"/api/generate-cover-letter\") {\n        const body = await asJson<CoverLetterRequest>(request);\n        requireFields(body, [\"resume\", \"job_description\", \"model_name\"]); // user_custom_prompt optional\n\n        const rendered = render(COVER_LETTER_TEMPLATE, {\n          resume: body.resume,\n          job_description: body.job_description,\n          user_custom_prompt: body.user_custom_prompt || \"(none)\",\n        });\n\n        const content = await chat(\n          env,\n          body.model_name,\n          [\n            {\n              role: \"system\",\n              content:\n                \"You are an expert cover letter writer at a top recruiting firm specializing in ATS optimization.\",\n            },\n            { role: \"user\", content: rendered },\n          ],\n          // use slightly higher temp for prose if you want; keeping 0.3 default\n          0.3,\n          8000\n        );\n\n        return ok(env, { cover_letter: content });\n      }\n\n      // Optimize Resume\n      if (request.method === \"POST\" && pathname === \"/api/optimize-resume\") {\n        const body = await asJson<ResumeOptimizationRequest>(request);\n        requireFields(body, [\"resume\", \"job_description\", \"model_name\", \"resume_section\"]); // user_custom_prompt optional\n\n        const sectionText = await extractResumeSection(env, body.resume, body.resume_section);\n\n        // func2 (existing points optimization)\n        const func2Json = await optimizeExistingPoints(\n          env,\n          sectionText,\n          body.job_description,\n          body.user_custom_prompt,\n          body.model_name\n        );\n\n        // main JSON (new points + keyword analysis)\n        const rendered = render(RESUME_OPTIMIZATION_TEMPLATE, {\n          resume_section: sectionText,\n          job_description: body.job_description,\n          user_custom_prompt: body.user_custom_prompt || \"(none)\",\n        });\n\n        const mainJson = await chat(\n          env,\n          body.model_name,\n          [\n            {\n              role: \"system\",\n              content:\n                \"You are an expert resume analyst and career coach with deep experience in talent acquisition and job matching.\",\n            },\n            { role: \"user\", content: rendered },\n          ],\n          0.3,\n          8000\n        );\n\n        return ok(env, {\n          Resume_Optimization: func2Json, // mirrors your Python \"optimized_resume_points\"\n          Remaining_Results: mainJson,    // mirrors your Python \"response.content\"\n          section_extracted: sectionText, // helpful for debugging\n        });\n      }\n\n      // Interview Prep\n      if (request.method === \"POST\" && pathname === \"/api/interview-prep\") {\n        const body = await asJson<InterviewPrepRequest>(request);\n        requireFields(body, [\n          \"resume\",\n          \"job_description\",\n          \"model_name\",\n          \"interviewer_role\",\n          \"interviewer_profile\",\n          \"interview_duration\",\n          \"interview_description\",\n        ]); // user_custom_prompt optional\n\n        const rendered = render(INTERVIEW_PREP_TEMPLATE, {\n          resume: body.resume,\n          job_description: body.job_description,\n          interviewer_role: body.interviewer_role,\n          interviewer_profile: body.interviewer_profile,\n          interview_duration: body.interview_duration,\n          interview_description: body.interview_description,\n          user_custom_prompt: body.user_custom_prompt || \"(none)\",\n        });\n\n        const content = await chat(\n          env,\n          body.model_name,\n          [\n            {\n              role: \"system\",\n              content:\n                \"You are a senior interview coach. Provide targeted, JSON-only prep: question bank, key themes, and concise answer frameworks.\",\n            },\n            { role: \"user\", content: rendered },\n          ],\n          0.3,\n          8000\n        );\n\n        return ok(env, { interview_prep: content });\n      }\n\n      // Interview Simulation\n      if (request.method === \"POST\" && pathname === \"/api/interview-sim\") {\n        const body = await asJson<InterviewSimulationRequest>(request);\n        requireFields(body, [\n          \"resume\",\n          \"job_description\",\n          \"interview_type\",\n          \"interviewer_role\",\n          \"interviewer_profile\",\n          \"interview_duration\",\n          \"interview_description\",\n          \"model_name\",\n        ]); // user_custom_prompt optional\n\n        const rendered = render(INTERVIEW_SIM_TEMPLATE, {\n          resume: body.resume,\n          job_description: body.job_description,\n          interview_type: body.interview_type,\n          interviewer_role: body.interviewer_role,\n          interviewer_profile: body.interviewer_profile,\n          interview_duration: body.interview_duration,\n          interview_description: body.interview_description,\n          user_custom_prompt: body.user_custom_prompt || \"(none)\",\n        });\n\n        const content = await chat(\n          env,\n          body.model_name,\n          [\n            {\n              role: \"system\",\n              content:\n                \"You are an experienced interviewer. Generate JSON-only simulation with agenda, tailored Qs, STAR responses, follow-ups, notes.\",\n            },\n            { role: \"user\", content: rendered },\n          ],\n          0.3,\n          8000\n        );\n\n        return ok(env, { interview_sim: content });\n      }\n\n      return err(env, 404, { error: \"Not found\" });\n    } catch (e: any) {\n      return err(env, 500, { error: e?.message || String(e) });\n    }\n  },\n};", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/Users/sagargopalasetti/interview-worker/src/index.ts\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/opt/homebrew/lib/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"/opt/homebrew/lib/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"/Users/sagargopalasetti/interview-worker/src/index.ts\";\n\t\t\t\tconst MIDDLEWARE_TEST_INJECT = \"__INJECT_FOR_TESTING_WRANGLER_MIDDLEWARE__\";\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/Users/sagargopalasetti/interview-worker/.wrangler/tmp/bundle-AyQuKx/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/opt/homebrew/lib/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/Users/sagargopalasetti/interview-worker/.wrangler/tmp/bundle-AyQuKx/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/Users/sagargopalasetti/interview-worker/.wrangler/tmp/bundle-AyQuKx/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n"],
  "mappings": ";;;;AAwBA,IAAM,UAAU;AAChB,IAAM,YAAY;AAClB,IAAM,gBAAgB;AAGtB,IAAM,SAAS;AAAA,EACb;AAAA,EACA;AAAA,EACA;AACF;AA8CA,IAAM,wBAAwB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAkD9B,IAAM,+BAA+B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA2GrC,IAAM,wBAAwB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAgG9B,IAAM,0BAA0B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA4NhC,IAAM,yBAAyB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA+G/B,SAAS,OAAO,KAAa,MAA2D;AACtF,SAAO,IAAI,QAAQ,cAAc,CAAC,GAAG,MAAM,OAAO,KAAK,CAAC,KAAK,EAAE,CAAC;AAClE;AAFS;AAOT,eAAe,KACb,KACA,WACA,UACA,cAAc,KACd,aAAa,KACI;AACjB,MAAI,cAAc,iBAAiB;AACjC,QAAI,CAAC,IAAI,iBAAkB,OAAM,IAAI,MAAM,qDAAqD;AAChG,UAAMA,QAAO,MAAM,MAAM,eAAe;AAAA,MACtC,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,eAAe,UAAU,IAAI,gBAAgB;AAAA,QAC7C,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU,EAAE,OAAO,iBAAiB,aAAa,YAAY,SAAS,CAAC;AAAA,IACpF,CAAC;AACD,QAAI,CAACA,MAAK,GAAI,OAAM,IAAI,MAAM,kBAAkBA,MAAK,MAAM,KAAK,MAAMA,MAAK,KAAK,CAAC,EAAE;AACnF,UAAMC,QAAY,MAAMD,MAAK,KAAK;AAClC,WAAOC,OAAM,UAAU,CAAC,GAAG,SAAS,WAAW;AAAA,EACjD;AAGA,MAAI,CAAC,IAAI,aAAc,OAAM,IAAI,MAAM,0BAA0B;AACjE,QAAM,OAAO,MAAM,MAAM,WAAW;AAAA,IAClC,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,eAAe,UAAU,IAAI,YAAY;AAAA,MACzC,gBAAgB;AAAA,IAClB;AAAA,IACA,MAAM,KAAK,UAAU,EAAE,OAAO,WAAW,aAAa,YAAY,SAAS,CAAC;AAAA,EAC9E,CAAC;AACD,MAAI,CAAC,KAAK,GAAI,OAAM,IAAI,MAAM,cAAc,KAAK,MAAM,KAAK,MAAM,KAAK,KAAK,CAAC,EAAE;AAC/E,QAAM,OAAY,MAAM,KAAK,KAAK;AAClC,SAAO,MAAM,UAAU,CAAC,GAAG,SAAS,WAAW;AACjD;AAnCe;AAwCf,eAAe,OAAU,SAA8B;AACrD,QAAM,KAAK,QAAQ,QAAQ,IAAI,cAAc,KAAK;AAClD,MAAI,CAAC,GAAG,SAAS,kBAAkB,EAAG,OAAM,IAAI,MAAM,sBAAsB;AAE5E,SAAQ,MAAM,QAAQ,KAAK;AAC7B;AALe;AAOf,SAAS,cAAc,KAA8B,MAAgB;AACnE,QAAM,UAAU,KAAK,OAAO,CAAC,MAAM,IAAI,CAAC,MAAM,UAAa,IAAI,CAAC,MAAM,QAAQ,IAAI,CAAC,MAAM,EAAE;AAC3F,MAAI,QAAQ,OAAQ,OAAM,IAAI,MAAM,YAAY,QAAQ,KAAK,IAAI,CAAC,EAAE;AACtE;AAHS;AAKT,SAAS,YAAY,KAAU;AAC7B,QAAM,IAAI,IAAI,QAAQ;AACtB,IAAE,IAAI,+BAA+B,IAAI,kBAAkB,GAAG;AAC9D,IAAE,IAAI,gCAAgC,kBAAkB;AACxD,IAAE,IAAI,gCAAgC,6BAA6B;AACnE,IAAE,IAAI,0BAA0B,OAAO;AACvC,SAAO;AACT;AAPS;AAST,SAAS,SAAS,KAAU,KAAe;AACzC,QAAM,MAAM,IAAI,SAAS,IAAI,MAAM,GAAG;AACtC,cAAY,GAAG,EAAE,QAAQ,CAAC,GAAG,MAAM,IAAI,QAAQ,IAAI,GAAG,CAAC,CAAC;AACxD,SAAO;AACT;AAJS;AAMT,SAAS,GAAG,KAAU,MAAe,SAAS,KAAK;AACjD,SAAO,SAAS,KAAK,IAAI,SAAS,KAAK,UAAU,IAAI,GAAG,EAAE,QAAQ,SAAS,EAAE,gBAAgB,QAAQ,EAAE,CAAC,CAAC;AAC3G;AAFS;AAGT,SAAS,IAAI,KAAU,QAAgB,MAAe;AACpD,SAAO,SAAS,KAAK,IAAI,SAAS,KAAK,UAAU,IAAI,GAAG,EAAE,QAAQ,SAAS,EAAE,gBAAgB,QAAQ,EAAE,CAAC,CAAC;AAC3G;AAFS;AAOT,eAAe,qBAAqB,KAAU,WAAmB,aAAsC;AACrG,QAAM,SAAS;AAAA,qCACoB,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA,EAK9C,SAAS;AAAA;AAAA,oCAEyB,WAAW;AAAA,IAC3C,KAAK;AAEP,QAAM,UAAU,MAAM;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,MACE,EAAE,MAAM,UAAU,SAAS,oCAAoC;AAAA,MAC/D,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,IAClC;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,UAAQ,WAAW,IAAI,KAAK;AAC9B;AAxBe;AA6Bf,eAAe,uBACb,KACA,gBACA,iBACA,oBACA,YACiB;AACjB,QAAM,WAAW,OAAO,uBAAuB;AAAA,IAC7C;AAAA,IACA;AAAA,IACA,oBAAoB,sBAAsB;AAAA,EAC5C,CAAC;AAED,SAAO,MAAM;AAAA,IACX;AAAA,IACA;AAAA,IACA;AAAA,MACE;AAAA,QACE,MAAM;AAAA,QACN,SACE;AAAA,MACJ;AAAA,MACA,EAAE,MAAM,QAAQ,SAAS,SAAS;AAAA,IACpC;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AA3Be;AAgCf,IAAO,cAAQ;AAAA,EACb,MAAM,MAAM,SAAkB,KAA6B;AACzD,QAAI,QAAQ,WAAW,UAAW,QAAO,SAAS,KAAK,IAAI,SAAS,MAAM,EAAE,QAAQ,IAAI,CAAC,CAAC;AAE1F,UAAM,EAAE,SAAS,IAAI,IAAI,IAAI,QAAQ,GAAG;AAExC,QAAI;AAEF,UAAI,QAAQ,WAAW,SAAS,aAAa,KAAK;AAChD,eAAO,GAAG,KAAK,EAAE,SAAS,gBAAgB,CAAC;AAAA,MAC7C;AAGA,UAAI,QAAQ,WAAW,SAAS,aAAa,eAAe;AAC1D,eAAO,GAAG,KAAK,EAAE,QAAQ,OAAO,CAAC;AAAA,MACnC;AAGA,UAAI,QAAQ,WAAW,UAAU,aAAa,8BAA8B;AAC1E,cAAM,OAAO,MAAM,OAA2B,OAAO;AACrD,sBAAc,MAAM,CAAC,UAAU,mBAAmB,YAAY,CAAC;AAE/D,cAAM,WAAW,OAAO,uBAAuB;AAAA,UAC7C,QAAQ,KAAK;AAAA,UACb,iBAAiB,KAAK;AAAA,UACtB,oBAAoB,KAAK,sBAAsB;AAAA,QACjD,CAAC;AAED,cAAM,UAAU,MAAM;AAAA,UACpB;AAAA,UACA,KAAK;AAAA,UACL;AAAA,YACE;AAAA,cACE,MAAM;AAAA,cACN,SACE;AAAA,YACJ;AAAA,YACA,EAAE,MAAM,QAAQ,SAAS,SAAS;AAAA,UACpC;AAAA;AAAA,UAEA;AAAA,UACA;AAAA,QACF;AAEA,eAAO,GAAG,KAAK,EAAE,cAAc,QAAQ,CAAC;AAAA,MAC1C;AAGA,UAAI,QAAQ,WAAW,UAAU,aAAa,wBAAwB;AACpE,cAAM,OAAO,MAAM,OAAkC,OAAO;AAC5D,sBAAc,MAAM,CAAC,UAAU,mBAAmB,cAAc,gBAAgB,CAAC;AAEjF,cAAM,cAAc,MAAM,qBAAqB,KAAK,KAAK,QAAQ,KAAK,cAAc;AAGpF,cAAM,YAAY,MAAM;AAAA,UACtB;AAAA,UACA;AAAA,UACA,KAAK;AAAA,UACL,KAAK;AAAA,UACL,KAAK;AAAA,QACP;AAGA,cAAM,WAAW,OAAO,8BAA8B;AAAA,UACpD,gBAAgB;AAAA,UAChB,iBAAiB,KAAK;AAAA,UACtB,oBAAoB,KAAK,sBAAsB;AAAA,QACjD,CAAC;AAED,cAAM,WAAW,MAAM;AAAA,UACrB;AAAA,UACA,KAAK;AAAA,UACL;AAAA,YACE;AAAA,cACE,MAAM;AAAA,cACN,SACE;AAAA,YACJ;AAAA,YACA,EAAE,MAAM,QAAQ,SAAS,SAAS;AAAA,UACpC;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAEA,eAAO,GAAG,KAAK;AAAA,UACb,qBAAqB;AAAA;AAAA,UACrB,mBAAmB;AAAA;AAAA,UACnB,mBAAmB;AAAA;AAAA,QACrB,CAAC;AAAA,MACH;AAGA,UAAI,QAAQ,WAAW,UAAU,aAAa,uBAAuB;AACnE,cAAM,OAAO,MAAM,OAA6B,OAAO;AACvD,sBAAc,MAAM;AAAA,UAClB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF,CAAC;AAED,cAAM,WAAW,OAAO,yBAAyB;AAAA,UAC/C,QAAQ,KAAK;AAAA,UACb,iBAAiB,KAAK;AAAA,UACtB,kBAAkB,KAAK;AAAA,UACvB,qBAAqB,KAAK;AAAA,UAC1B,oBAAoB,KAAK;AAAA,UACzB,uBAAuB,KAAK;AAAA,UAC5B,oBAAoB,KAAK,sBAAsB;AAAA,QACjD,CAAC;AAED,cAAM,UAAU,MAAM;AAAA,UACpB;AAAA,UACA,KAAK;AAAA,UACL;AAAA,YACE;AAAA,cACE,MAAM;AAAA,cACN,SACE;AAAA,YACJ;AAAA,YACA,EAAE,MAAM,QAAQ,SAAS,SAAS;AAAA,UACpC;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAEA,eAAO,GAAG,KAAK,EAAE,gBAAgB,QAAQ,CAAC;AAAA,MAC5C;AAGA,UAAI,QAAQ,WAAW,UAAU,aAAa,sBAAsB;AAClE,cAAM,OAAO,MAAM,OAAmC,OAAO;AAC7D,sBAAc,MAAM;AAAA,UAClB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF,CAAC;AAED,cAAM,WAAW,OAAO,wBAAwB;AAAA,UAC9C,QAAQ,KAAK;AAAA,UACb,iBAAiB,KAAK;AAAA,UACtB,gBAAgB,KAAK;AAAA,UACrB,kBAAkB,KAAK;AAAA,UACvB,qBAAqB,KAAK;AAAA,UAC1B,oBAAoB,KAAK;AAAA,UACzB,uBAAuB,KAAK;AAAA,UAC5B,oBAAoB,KAAK,sBAAsB;AAAA,QACjD,CAAC;AAED,cAAM,UAAU,MAAM;AAAA,UACpB;AAAA,UACA,KAAK;AAAA,UACL;AAAA,YACE;AAAA,cACE,MAAM;AAAA,cACN,SACE;AAAA,YACJ;AAAA,YACA,EAAE,MAAM,QAAQ,SAAS,SAAS;AAAA,UACpC;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAEA,eAAO,GAAG,KAAK,EAAE,eAAe,QAAQ,CAAC;AAAA,MAC3C;AAEA,aAAO,IAAI,KAAK,KAAK,EAAE,OAAO,YAAY,CAAC;AAAA,IAC7C,SAAS,GAAQ;AACf,aAAO,IAAI,KAAK,KAAK,EAAE,OAAO,GAAG,WAAW,OAAO,CAAC,EAAE,CAAC;AAAA,IACzD;AAAA,EACF;AACF;;;AC39BA,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,UAAE;AACD,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;AAAA,QAAC;AAAA,MACtC;AAAA,IACD,SAAS,GAAG;AACX,cAAQ,MAAM,4CAA4C,CAAC;AAAA,IAC5D;AAAA,EACD;AACD,GAb8B;AAe9B,IAAO,6CAAQ;;;ACRf,SAAS,YAAY,GAAmB;AACvC,SAAO;AAAA,IACN,MAAM,GAAG;AAAA,IACT,SAAS,GAAG,WAAW,OAAO,CAAC;AAAA,IAC/B,OAAO,GAAG;AAAA,IACV,OAAO,GAAG,UAAU,SAAY,SAAY,YAAY,EAAE,KAAK;AAAA,EAChE;AACD;AAPS;AAUT,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,SAAS,GAAQ;AAChB,UAAM,QAAQ,YAAY,CAAC;AAC3B,WAAO,SAAS,KAAK,OAAO;AAAA,MAC3B,QAAQ;AAAA,MACR,SAAS,EAAE,+BAA+B,OAAO;AAAA,IAClD,CAAC;AAAA,EACF;AACD,GAV8B;AAY9B,IAAO,2CAAQ;;;ACzBJ,IAAM,mCAAmC;AAAA,EAE9B;AAAA,EAAyB;AAC3C;AACA,IAAO,sCAAQ;;;ACcnB,IAAM,wBAAsC,CAAC;AAKtC,SAAS,uBAAuB,MAAqC;AAC3E,wBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB;AAShB,SAAS,uBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;AAAA,IACxC;AAAA,IACA,KAAK,YAAY,QAAQ;AACxB,aAAO,uBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;AAAA,IACtE;AAAA,EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS;AAiBF,SAAS,kBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAO,uBAAuB,SAAS,KAAK,KAAK,UAAU;AAAA,IAC1D,GAAG;AAAA,IACH;AAAA,EACD,CAAC;AACF;AAXgB;;;AC3ChB,IAAM,iCAAN,MAAM,gCAA8D;AAAA,EAGnE,YACU,eACA,MACT,SACC;AAHQ;AACA;AAGT,SAAK,WAAW;AAAA,EACjB;AAAA,EArBD,OAYoE;AAAA;AAAA;AAAA,EAC1D;AAAA,EAUT,UAAU;AACT,QAAI,EAAE,gBAAgB,kCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;AAAA,IACzC;AAEA,SAAK,SAAS;AAAA,EACf;AACD;AAEA,SAAS,oBAAoB,QAA0C;AAEtE,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAEA,QAAM,kBAA+C,gCACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;AAAA,EACtC,GATqD;AAWrD,SAAO;AAAA,IACN,GAAG;AAAA,IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gCAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAI;AAAA,YACtB,KAAK,IAAI;AAAA,YACT,KAAK,QAAQ;AAAA,YACb,MAAM;AAAA,YAAC;AAAA,UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;AAAA,QAC7C;AAAA,MACD,GAT+B;AAU/B,aAAO,kBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;AAAA,IACxE;AAAA,EACD;AACD;AAxCS;AA0CT,SAAS,qBACR,OAC8B;AAE9B,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAGA,SAAO,cAAc,MAAM;AAAA,IAC1B,mBAAyE,wBACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;AAAA,MACvE;AACA,aAAO,MAAM,MAAM,OAAO;AAAA,IAC3B,GAXyE;AAAA,IAazE,cAA0B,wBAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAI;AAAA,UACtB,KAAK,IAAI;AAAA,UACT,KAAK,QAAQ;AAAA,UACb,MAAM;AAAA,UAAC;AAAA,QACR;AACA,eAAO,MAAM,UAAU,UAAU;AAAA,MAClC;AAAA,IACD,GAT0B;AAAA,IAW1B,MAAM,SAAwD;AAC7D,aAAO;AAAA,QACN;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MACN;AAAA,IACD;AAAA,EACD;AACD;AAnDS;AAqDT,IAAI;AACJ,IAAI,OAAO,wCAAU,UAAU;AAC9B,kBAAgB,oBAAoB,mCAAK;AAC1C,WAAW,OAAO,wCAAU,YAAY;AACvC,kBAAgB,qBAAqB,mCAAK;AAC3C;AACA,IAAO,kCAAQ;",
  "names": ["resp", "data"]
}
